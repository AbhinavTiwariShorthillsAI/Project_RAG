# ğŸ§  PROJECT_RAG â€“ Semantic Retrieval-Augmented Generation (RAG) System for Historical Q&A

This project is a **Retrieval-Augmented Generation (RAG)** system designed to answer questions from historical documents (like World War history) using local models and open-source tools.

---

## ğŸš€ Key Features

- ğŸ” **Semantic Chunking**: Smart text splitting using `RecursiveCharacterTextSplitter`
- ğŸ§  **Embeddings**: Generated with `intfloat/e5-base-v2`
- ğŸ” **Weaviate Vector DB**: Fast and scalable vector storage + search
- ğŸ§® **Cross-Encoder Re-ranking**: Improves retrieval accuracy
- ğŸ’¬ **Local LLM (LLaMA3 via Ollama)**: Offline inference with high quality
- ğŸ“Š **Evaluation Metrics**: ROUGE-L, cosine similarity, BERTScore-F1
- ğŸ§ª **Streamlit UI**: Ask questions interactively with real-time answers

---

## ğŸ§± Project Structure

```
PROJECT_RAG/
â”œâ”€â”€ app/                    # Core logic
â”‚   â””â”€â”€ embedding.py        # Chunk creation + upload
â”‚
â”œâ”€â”€ streamlit_app/
â”‚   â””â”€â”€ app.py              # Streamlit chatbot
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ question_gen.py     # Auto-generate Q&A
â”‚   â”œâ”€â”€ test.py             # Evaluation pipeline
â”‚   â””â”€â”€ testing_data.py     # Predict answers for questions
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ modern_history_combined.txt
â”‚   â”œâ”€â”€ qa_dataset_1000.csv
â”‚   â”œâ”€â”€ qa_with_predictions.xlsx
â”‚   â””â”€â”€ qa_evaluated_scores.xlsx
â”‚
â”œâ”€â”€ .env                    # Environment variables
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1. Clone and Setup

```bash
git clone https://github.com/AbhinavTiwariShorthillsAI/PROJECT_RAG.git
cd PROJECT_RAG
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. Configure `.env`

Create a `.env` file with:

```
OLLAMA_MODEL=llama3
DATASET_PATH=data/qa_dataset_1000.csv
HISTORY_FILE=conversation_history.json
```

### 3. Start Ollama and Weaviate

```bash
# Start Ollama (with LLaMA3 model)
ollama run llama3

# Start Weaviate with Docker
docker run -d -p 8080:8080 semitechnologies/weaviate:latest
```

---

## ğŸ§ª How to Use

### âœ… Index Text into Weaviate

```bash
python app/embedding.py
```

### âœ… Generate Questions + Answers

```bash
python scripts/question_gen.py
```

### âœ… Generate Predictions for Existing Qs

```bash
python scripts/testing_data.py
```

### âœ… Evaluate Model Accuracy

```bash
python scripts/test.py
```

### âœ… Launch Streamlit Chatbot

```bash
streamlit run streamlit_app/app.py
```

---

## ğŸ“Š Evaluation Metrics

| Metric           | Description                                 |
|------------------|---------------------------------------------|
| **ROUGE-L**      | Overlap in word sequences (surface match)   |
| **Cosine Similarity** | Vector-based semantic similarity       |
| **BERTScore F1** | Deep contextual alignment with reference    |
| **Final Score**  | Weighted composite of all above             |

Grades (A to F) are computed from final score thresholds.

---

## ğŸ“¦ Requirements

Install all via:

```bash
pip install -r requirements.txt
```

---


## ğŸ¤ Contributions

PRs and issues are welcome! Please open a discussion if you'd like to improve this project.

---

## ğŸ“„ License

MIT License Â© 2025 [Your Name]
