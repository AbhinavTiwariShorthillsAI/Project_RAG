{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa23bf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Collecting google-api-core\n",
      "  Using cached google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15\n",
      "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.2/316.2 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-api-python-client\n",
      "  Using cached google_api_python_client-2.168.0-py3-none-any.whl (13.3 MB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Collecting google-auth>=2.15.0\n",
      "  Using cached google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from google-generativeai) (4.13.2)\n",
      "Collecting protobuf\n",
      "  Using cached protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Collecting requests<3.0.0,>=2.18.0\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.33.1\n",
      "  Using cached pydantic_core-2.33.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Collecting typing-inspection>=0.4.0\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Using cached grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2\n",
      "  Using cached grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyasn1<0.7.0,>=0.6.1\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.6/159.6 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, uritemplate, typing-inspection, tqdm, pyparsing, pydantic-core, pyasn1, protobuf, idna, grpcio, charset-normalizer, certifi, cachetools, annotated-types, rsa, requests, pydantic, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed annotated-types-0.7.0 cachetools-5.5.2 certifi-2025.4.26 charset-normalizer-3.4.1 google-ai-generativelanguage-0.6.15 google-api-core-2.24.2 google-api-python-client-2.168.0 google-auth-2.39.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.71.0 grpcio-status-1.71.0 httplib2-0.22.0 idna-3.10 proto-plus-1.26.1 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.3 pydantic-core-2.33.1 pyparsing-3.2.3 requests-2.32.3 rsa-4.9.1 tqdm-4.67.1 typing-inspection-0.4.0 uritemplate-4.1.1 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610149a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shtlp_0012/codes/Project_RAG/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wind clawed at Ignis, ripping at the obsidian scales on his chest like a ravenous beast. Below, the jagged peaks of the Dragon's Tooth Mountains plunged into a swirling abyss of storm clouds. He hadn't flown this low in centuries, not since... not since he'd lost everything.\n",
      "\n",
      "The memory, a burning ember in his heart, flickered to life. The lush valley, teeming with life, the soft laughter of his clutchlings, the warmth of his mate's scales pressed against his. All gone. Scourged by the iron teeth and fire of the humans.\n",
      "\n",
      "A guttural rumble clawed its way from his throat. He had vowed vengeance then, a promise carved into the very core of his being. But centuries had dulled the rage, leaving behind only a cold, gnawing ache.\n",
      "\n",
      "He spotted it then, a faint flicker of light nestled in the crook of the mountain, like a single ember refusing to be extinguished. A village. Human village.\n",
      "\n",
      "His claws tightened on the winds, pulling him towards the light. The scent of smoke, of fear, filled his nostrils. He could feel the trembling of tiny hearts below, the frantic prayers whispered into the encroaching darkness.\n",
      "\n",
      "This was it. This was the moment. He could unleash the inferno within, paint the sky crimson with their screams, and finally satiate the centuries-old hunger for retribution.\n",
      "\n",
      "He drew closer, his shadow swallowing the village whole. The flickering flames of the hearth fires danced like mocking imps, inviting him to join their fiery feast. He opened his maw, the raw, untamed power of his breath gathering within.\n",
      "\n",
      "And then he saw her.\n",
      "\n",
      "A small girl, no older than five, stood in the center of the village square, clutching a crudely fashioned wooden dragon. Her eyes, wide with a fear that mirrored his own centuries ago, were fixed on him.\n",
      "\n",
      "Ignis felt something crack within him. Not the crushing blow of a dragon slayer, but a subtle, almost imperceptible fracture. The rage that had fueled him for so long wavered, replaced by a fleeting, unfamiliar emotion.\n",
      "\n",
      "He saw his own hatchlings in her innocent gaze, their unformed wings, their trusting faces. He saw the life he had lost, not just the destruction of his home, but the potential for peace, for understanding.\n",
      "\n",
      "He held his breath, the fire building within him threatening to consume him. He could still do it. Erase them all. End the cycle of hatred.\n",
      "\n",
      "But as the little girl raised the wooden dragon to him, a silent offering, something shifted within his ancient soul.\n",
      "\n",
      "The fire subsided. He closed his maw.\n",
      "\n",
      "With a beat of his powerful wings, he turned, the wind screaming in protest at his defiance. He soared back into the storm, leaving the village trembling in the wake of his passing.\n",
      "\n",
      "He had not found vengeance. He had found something far more terrifying: the possibility of forgiveness.\n",
      "\n",
      "The ache remained, but now it was tinged with a sliver of hope. Perhaps, he thought, staring into the endless storm, perhaps the fire could be quenched, not with blood, but with something else entirely. Perhaps, one day, dragons and humans could learn to live under the same sky.\n",
      "\n",
      "But tonight, he could only fly, lost in the turbulent sky, haunted by the ghost of a fire that was never unleashed, and the small, unwavering hope flickering in the heart of a dragon who had chosen peace over destruction.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  \n",
    "\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "response = model.generate_content(\n",
    "    \"Write a dramatic short story about a dragon.\"\n",
    ")\n",
    "\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "074c16c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp310-cp310-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting Pillow\n",
      "  Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./venv/lib/python3.10/site-packages (from sentence-transformers) (4.13.2)\n",
      "Collecting transformers<5.0.0,>=4.41.0\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0\n",
      "  Using cached torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (865.2 MB)\n",
      "Collecting huggingface-hub>=0.20.0\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Collecting numpy<3.0,>=1.25.0\n",
      "  Downloading numpy-2.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2\n",
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1\n",
      "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77\n",
      "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2\n",
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77\n",
      "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6\n",
      "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4\n",
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Collecting triton==3.3.0\n",
      "  Using cached triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2\n",
      "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.6.85\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in ./venv/lib/python3.10/site-packages (from triton==3.3.0->torch>=1.11.0->sentence-transformers) (59.6.0)\n",
      "Collecting tokenizers<0.22,>=0.21\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Collecting safetensors>=0.4.3\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, threadpoolctl, sympy, safetensors, regex, pyyaml, Pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, joblib, fsspec, filelock, scipy, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, huggingface-hub, faiss-cpu, tokenizers, scikit-learn, nvidia-cusolver-cu12, transformers, torch, sentence-transformers\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.2.1 faiss-cpu-1.11.0 filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.2 jinja2-3.1.6 joblib-1.4.2 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.5 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-4.1.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.21.1 torch-2.7.0 transformers-4.51.3 triton-3.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "203c7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Sherlock_Holmes.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "def split_text(text, chunk_size=500, overlap=50):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start = end - overlap  # small overlap to avoid breaking context\n",
    "    return chunks\n",
    "\n",
    "# Example\n",
    "chunks = split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6cd049b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 41/41 [00:20<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index built successfully!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# 1. Create Embeddings\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = embed_model.encode(chunks, show_progress_bar=True)\n",
    "\n",
    "# 2. Ensure float32 for FAISS\n",
    "embeddings = np.array(embeddings).astype(np.float32)\n",
    "\n",
    "# 3. Build FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"✅ FAISS index built successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3fd444d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g his\\nface. And here he comes, if I am not mistaken, to resolve all our\\ndoubts.”\\n\\nAs he spoke there was the sharp sound of horses’ hoofs and grating\\nwheels against the curb, followed by a sharp pull at the bell. Holmes\\nwhistled.\\n\\n“A pair, by the sound,” said he. “Yes,” he continued, glancing out of\\nthe window. “A nice little brougham and a pair of beauties. A hundred\\nand fifty guineas apiece. There’s money in this case, Watson, if there\\nis nothing else.”\\n\\n“I think that I had better go, Holmes.”\\n', 'und, and I could see in the gas-light\\nthat every vestige of colour had been driven from his face.\\n\\n“Who are you, then? What do you want?” he asked in a quavering voice.\\n\\n“You will excuse me,” said Holmes blandly, “but I could not help\\noverhearing the questions which you put to the salesman just now. I\\nthink that I could be of assistance to you.”\\n\\n“You? Who are you? How could you know anything of the matter?”\\n\\n“My name is Sherlock Holmes. It is my business to know what other\\npeople don’t know.”\\n\\n', 'nth then.”\\n\\n“How did he come?”\\n\\n“In answer to an advertisement.”\\n\\n“Was he the only applicant?”\\n\\n“No, I had a dozen.”\\n\\n“Why did you pick him?”\\n\\n“Because he was handy and would come cheap.”\\n\\n“At half wages, in fact.”\\n\\n“Yes.”\\n\\n“What is he like, this Vincent Spaulding?”\\n\\n“Small, stout-built, very quick in his ways, no hair on his face,\\nthough he’s not short of thirty. Has a white splash of acid upon his\\nforehead.”\\n\\nHolmes sat up in his chair in considerable excitement. “I thought as\\nmuch,” said he. ']\n"
     ]
    }
   ],
   "source": [
    "def search_index(query, top_k=5):\n",
    "    query_embedding = embed_model.encode([query])\n",
    "    distances, indices = index.search(np.array(query_embedding), top_k)\n",
    "    results = [chunks[i] for i in indices[0]]\n",
    "    return results\n",
    "\n",
    "# Example\n",
    "relevant_chunks = search_index(\"Holmes\", top_k=3)\n",
    "print(relevant_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0716811e",
   "metadata": {},
   "outputs": [
    {
     "ename": "DeadlineExceeded",
     "evalue": "504 Deadline Exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDeadlineExceeded\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m full_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(relevant_chunks)\n\u001b[1;32m      2\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mBased on the following document content, answer the user\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms question:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfull_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion: What can we learn about Holmes’s personality from his investigation methods?. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnswer:\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDeadlineExceeded\u001b[0m: 504 Deadline Exceeded"
     ]
    }
   ],
   "source": [
    "full_context = \"\\n\".join(relevant_chunks)\n",
    "prompt = f\"\"\"\n",
    "Based on the following document content, answer the user's question:\\n\\n{full_context}\\n\\nQuestion: What can we learn about Holmes’s personality from his investigation methods?. \\nAnswer:\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a5e7435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Schema created successfully!\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.Client(url=\"http://localhost:8080\")\n",
    "\n",
    "# Define the schema\n",
    "class_obj = {\n",
    "    \"class\": \"HolmesChunk\",  # You can name it whatever you want\n",
    "    \"vectorizer\": \"none\",  # Important! We provide our own vectors\n",
    "    \"properties\": [\n",
    "        {\n",
    "            \"name\": \"text\",\n",
    "            \"dataType\": [\"text\"]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the schema\n",
    "client.schema.create_class(class_obj)\n",
    "\n",
    "print(\"✅ Schema created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e263a6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All data inserted into Weaviate!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Make sure embeddings are float32\n",
    "embeddings = np.array(embeddings).astype(np.float32)\n",
    "\n",
    "for chunk, embedding in zip(chunks, embeddings):\n",
    "    client.data_object.create(\n",
    "        data_object={\"text\": chunk},\n",
    "        class_name=\"HolmesChunk\",\n",
    "        vector=embedding.tolist()\n",
    "    )\n",
    "\n",
    "print(\"✅ All data inserted into Weaviate!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "84f81445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "und, and I could see in the gas-light\n",
      "that every vestige of colour had been driven from his face.\n",
      "\n",
      "“Who are you, then? What do you want?” he asked in a quavering voice.\n",
      "\n",
      "“You will excuse me,” said Holmes blandly, “but I could not help\n",
      "overhearing the questions which you put to the salesman just now. I\n",
      "think that I could be of assistance to you.”\n",
      "\n",
      "“You? Who are you? How could you know anything of the matter?”\n",
      "\n",
      "“My name is Sherlock Holmes. It is my business to know what other\n",
      "people don’t know.”\n",
      "\n",
      "\n",
      "\n",
      "Result 2:\n",
      "t. He used to make merry over the cleverness of women, but I\n",
      "have not heard him do it of late. And when he speaks of Irene Adler, or\n",
      "when he refers to her photograph, it is always under the honourable\n",
      "title of _the_ woman.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "II. THE RED-HEADED LEAGUE\n",
      "\n",
      "\n",
      " I had called upon my friend, Mr. Sherlock Holmes, one day in the\n",
      " autumn of last year and found him in deep conversation with a very\n",
      " stout, florid-faced, elderly gentleman with fiery red hair. With an\n",
      " apology for my intrusion, I was about to \n",
      "\n",
      "Result 3:\n",
      "o the extreme limits of his\n",
      "reason. Then, suddenly springing to his feet, he beat his head against\n",
      "the wall with such force that we both rushed upon him and tore him away\n",
      "to the centre of the room. Sherlock Holmes pushed him down into the\n",
      "easy-chair and, sitting beside him, patted his hand and chatted with\n",
      "him in the easy, soothing tones which he knew so well how to employ.\n",
      "\n",
      "“You have come to me to tell your story, have you not?” said he. “You\n",
      "are fatigued with your haste. Pray wait until you ha\n",
      "\n",
      "Result 4:\n",
      "net\n",
      "   XII.   The Adventure of the Copper Beeches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I. A SCANDAL IN BOHEMIA\n",
      "\n",
      "\n",
      "I.\n",
      "\n",
      "To Sherlock Holmes she is always _the_ woman. I have seldom heard him\n",
      "mention her under any other name. In his eyes she eclipses and\n",
      "predominates the whole of her sex. It was not that he felt any emotion\n",
      "akin to love for Irene Adler. All emotions, and that one particularly,\n",
      "were abhorrent to his cold, precise but admirably balanced mind. He\n",
      "was, I take it, the most perfect reasoning and observing machine that\n",
      "the\n",
      "\n",
      "Result 5:\n",
      "h to hear your real, real opinion.”\n",
      "\n",
      "“Upon what point?”\n",
      "\n",
      "“In your heart of hearts, do you think that Neville is alive?”\n",
      "\n",
      "Sherlock Holmes seemed to be embarrassed by the question. “Frankly,\n",
      "now!” she repeated, standing upon the rug and looking keenly down at\n",
      "him as he leaned back in a basket-chair.\n",
      "\n",
      "“Frankly, then, madam, I do not.”\n",
      "\n",
      "“You think that he is dead?”\n",
      "\n",
      "“I do.”\n",
      "\n",
      "“Murdered?”\n",
      "\n",
      "“I don’t say that. Perhaps.”\n",
      "\n",
      "“And on what day did he meet his death?”\n",
      "\n",
      "“On Monday.”\n",
      "\n",
      "“Then perhaps, Mr. Holmes, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. User asks a question\n",
    "query = \"Who was Sherlock Holmes?\"\n",
    "\n",
    "# 2. Embed the query\n",
    "query_embedding = embed_model.encode([query])\n",
    "query_embedding = np.array(query_embedding).astype(np.float32)\n",
    "\n",
    "# 3. Search Weaviate for similar chunks\n",
    "response = client.query.get(\n",
    "    \"HolmesChunk\",\n",
    "    [\"text\", \"_additional { vector }\"]\n",
    ").with_near_vector({\n",
    "    \"vector\": query_embedding[0]\n",
    "}).with_limit(5).do()\n",
    "\n",
    "# 4. Print the best matches\n",
    "for i, result in enumerate(response[\"data\"][\"Get\"][\"HolmesChunk\"]):\n",
    "    print(f\"Result {i+1}:\\n{result['text']}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f1495d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.schema.delete_all()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
